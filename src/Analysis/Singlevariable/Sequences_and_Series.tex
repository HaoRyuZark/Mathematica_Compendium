\newpage
\section{Sequences and Series}

A sequence is an ordered list of numbers, usually defined by a formula or a recurrence relation. It is 
one of the fundamental objects of study in mathematical analysis.

\subsection{Arithmetic Sequence}

An \emph{arithmetic sequence} is a sequence where the difference between consecutive terms is constant.

\[
    a_n = a_1 + (n - 1)d
\]

\begin{itemize}

    \item \(a_1\) is the first term

    \item \(d\) is the common difference \(d = a_{n + 1} - a_{n}\)

\end{itemize}

\textbf{Example:}

\[
    a_n = 3 + (n - 1) \cdot 2 = 2n + 1 \quad \text{(Odd numbers)}
\]

\subsection{Geometric Sequence}

A \emph{geometric sequence} is a sequence where each term is obtained by multiplying the previous term 
by a fixed non-zero constant.

\[
    a_n = a_1 \cdot r^{n-1}
\]

\begin{itemize}

    \item \(a_1\) is the first term

    \item \(r\) is the common ratio \(r = \frac{a_{n + 1}}{a_n}\)

\end{itemize}

\textbf{Example:}

\[
    a_n = 2 \cdot 3^{n-1} = 2, 6, 18, 54, \dots
\]

\subsection{Function Sequence}

A \emph{function sequence} is sequence composed of functions and its noted like:

\[
    {(f)}_n \text{with } x^t := \{ f: D\to R | \ f \text{ is a function}\}
\]

\subsection{Boundness of a Sequence}

To show the boundness of a sequence we can use the definition of the \emph{supremum} or \emph{infimum} and 
approximations. 

One useful definition is that a sequence is bounded below and above if 

\[
    |a_n| \le M, \forall n \ge 1
\]

\textbf{Example:}

Given is \(a_n = \frac{1}{2n + 3}\) 

\[
    \left| \frac{1}{2n + 3} \right| \le \frac{1}{2n + 3} < \frac{1}{2n} < \frac{1}{n} le 1
\]

Because, we have found a concrete bound we can state that the sequence is bounded. 

\subsection{Convergence}

A sequence \((a_n)\) \emph{converges} to a limit \(L\) if for every \(\varepsilon > 0\), there exists an 
integer \(n_0\) such that for all \(n \ge n_0\):

\[
    \forall \varepsilon > 0 \exists N \in \Naturals: \forall n \ge N |a_n - L| < \varepsilon
\]

In this case, we write:

\[
    \lim_{n \to \infty} a_n = L
\]

This also means that \(\{a_n - a\}_{n = 1}^{\infty}\) is a zero sequence.

\subsubsection{Properties of convergent Sequences}

Given the convergent sequences \(\{a_n\}_{n = 1}^{\infty}, \{b_n\}_{n = 1}^{\infty}\) with \(a\) and \(b\) as the respective limits. 
For a bounded sequence \(\{c_n\}_{n = 1}^{\infty}\) then the following applies:

\begin{itemize}

    \item \(\{a_n\}_{n = 1}^{\infty}\) is bounded 
    
    \item \(\{\alpha a_n + \beta b_n\}_{n = 1}^{\infty}, \alpha, \beta \in \Reals\) converges towards \(\alpha a + \beta b\)

    \item \(\{|a_n|\}_{n = 1}^{\infty}\) converges towards \(|a|\) and \(\{\sqrt{a_n}\}_{n = 1}^{\infty}\) towards \(\sqrt{|a|}\)

    \item \(\{a_n \cdot b_n\}_{n = 1}^{\infty}\) converges towards \(a \cdot b\)

    \item \(\{a_n \cdot c_n\}_{n = 1}^{\infty}\) is bounded 
    
    \item If \(a_n \ne 0, \forall n \in \Naturals\) and \(a \ne 0\) then \(\lim_{n \to \infty} \frac{1}{a_n} = \frac{1}{a}\)

\end{itemize}

\subsection{The limit of a Sequence is Unique}

Given a convergent sequence \(a_n\) then its limit is unique. 

\textbf{Proof:}

Suppose that \(a_n\) has two different limits \(a\) and \(b\). Let \( \varepsilon = \frac{|a - b|}{2} > 0\)

Because we have distinct limit we write 

\[
    \forall \varepsilon > 0 \exists i \in \Naturals: \forall i \ge N_1 |a_i - a| < \frac{|a - b|}{2}
\]

and 

\[
    \forall \varepsilon > 0 \exists j \in \Naturals: \forall j \ge N_2 |a_j - b| < \frac{|a - b|}{2}
\]

Let \(M = \max{N_1, N_2}\). Then 

\[
    |a - b| = |a - a_n + a_n - b| \le  |a_n - a| + |a_n - b| < 2 \varepsilon = \varepsilon > 0
\]

Thus, \(|a - b| < |a - b|\) and this is a contradiction. The limit must be unique.

\QED 

\subsection{Convergence by Power of One Half}

If for a sequence \(a_n\) the following holds then it converges 

\[
   | a_n  - a_{n + 1} | \le \frac{1}{2^n} 
\]

\subsection{Boundness of Convergent Sequences}

Let \(a_n\) be a convergent sequence then \(a_n\) is bounded 

\textbf{Proof:}

Because \(a_n\) converges, it has a limit \(a\). Now, let \(\varepsilon = 1\), and let us use the definition of convergence.

\begin{align*}
    -\varepsilon <|a_n - a| &< \varepsilon \\ 
   -1 < a_n - a &< 1 \\ 
    a - 1 , a_n  &< 1 + a \text{ for all } n > n_0 
\end{align*}

Until, this point we have proof the boundness for all \(n > n_0\). To guarantee that the sequence is also bounded 
for \( 1 \le n \le n_0 \) we define 

\[
    U := \max({x \mid x \in a_n , n \le n_0}, a + 1) 
\]

and

\[
    L := \min({x \mid x \in a_n, n \le n_0}, a - 1)
\]

Thus, our sequence is bounded

\[
    L \le a_n \le U
\]

\QED 

\subsection{Cauchy Sequence}

A sequence \((a_n)\) is a \emph{Cauchy sequence} if for every \(\varepsilon > 0\), there exists an 
integer \(n_0\) such that for all \(n, m \ge n_0\):

\[
    \forall \varepsilon > 0 \exists n,m,N \in \Naturals: |a_n - a_m| < \varepsilon\ \text{with } n, m \ge N
\]

Every convergent sequence is a Cauchy sequence. In complete metric spaces (like \(\Reals\)), the 
converse also holds.

\textbf{Example: Convergence Exercise}

Let \(a_i = \frac{1}{i}\) and \(\varepsilon = 0.01\). We want to find \(i_0\) such that:

\[
    \left|\frac{1}{n} - 0\right| < \varepsilon \implies \frac{1}{i} \le \frac{1}{n} < \varepsilon \rightarrow \frac{1}{\varepsilon} < n
\]
\[
    \Rightarrow \frac{1}{i} < 0.01 \Rightarrow i > 100
    \Rightarrow i_0 = 101
\]

\subsection{Proof that every Convergent Sequence is a Cauchy Sequence}

Given a sequence \(a_n\) then \(a_n\) is convergent if and only if it is a Cauchy sequence. 

\(\rightarrow :\) \(a_n\) is convergent therefore, the following holds 

\[
    \forall \varepsilon > 0 \exists N \in \Naturals: \forall n \ge N |a_n - L| < \varepsilon
\]

Thus, we can use the triangle inequality for our definition of the Cauchy sequence and the following 
definition 

\[
    |a_n - a| < \frac{\varepsilon}{2} 
\]
\[
    |a_m - a| < \frac{\varepsilon}{2} 
\]

This is allowed we know that \(a_n\) converges. We choose the max of each of the indices for which the inequality holds. Then

\[
    |a_n - a_m + a - a| \le |a_n - a| + |a_m - a| < 2\frac{\varepsilon}{2} = \varepsilon
\]

\(\leftarrow :\) \(a_n\) is a Cauchy sequence, thus 

\[
    \forall \varepsilon > 0 \exists n,m,N \in \Naturals: |a_n - a_m| < \varepsilon \text{ with } n, m \ge N
\]

\(a_n\) is bounded because else \( |a_n - a_m| < \varepsilon \) will not hold. Therefore, by Bolzano-Weierstraß Theorem 
it must converge 

\QED 

\subsection{Definition of \texorpdfstring{\(\varepsilon\)}{ε}-Neighborhood}

The \emph{\(\varepsilon\)-neighborhood} of a point \(a \in \Reals\) is the set:

\[
    B_\varepsilon(a) = \{x \in \Reals \mid |x - a| < \varepsilon\}
\]

This is the open interval \((a - \varepsilon, a + \varepsilon)\).

\subsection{Supremum, Infimum, Maximum and Minimum}

The \emph{supremum} \(\text{sup}\) of a set \(A \subseteq \Reals\) is the 
least upper bound: the smallest real number \(s\) such that \(a \le s\) for all \(a \in A\).

\[
    x \le s, \forall x \in A 
\]

\[
    x \le s', \forall x \in A \implies s' \ge s
\]


The \emph{maximum} is the largest element in the set, if it exists.

The \emph{minimum} is the smallest element in the set, if it exists.

Finally we define \(\text{sup} \emptyset := - \infty\) and \(\text{inf} \emptyset := +\infty\)

\textbf{Example I:}

For \(A = (0,1)\):

\begin{itemize}

    \item \(\sup A = 1\) (not in \(A\))

    \item \(\inf A = 0\) (not in \(A\))

    \item \(\max A\) and \(\min A\) do not exist

\end{itemize}

\textbf{Example II:}

For \((0, 5)\) and \((0,5]\), the supremum is 5.

\textbf{Example III:}

For the real numbers we can define \(\sqrt{2}\) as the supremum of the set \(\{x \in \Reals \mid x^2 < 2\}\).

The \emph{infimum} \(\text{inf}\) of a set \(A\) is the greatest lower bound: 
the largest number \(t\) such that \(a \ge t\) for all \(a \in A\). 

\[
    x \ge s, \forall x \in A 
\]

\[
    x \ge s', \forall x \in A \implies s' \le s
\]

\textbf{Example IV:}

Prove that \(\sup \{\frac{n}{n + 1 \mid n \in \Naturals}\} = 1\).  

To prove we need to show that 1 is an upper bound and then that \(\forall \varepsilon > 0\) \(a - \varepsilon\) is not 
an upper bound.

\begin{align*}
    1 &\ge \frac{n}{n + 1} \\ 
    n + 1 &\ge n
\end{align*}

Thus, 1 is in fact an upper bound. 

For the second part, let \(\varepsilon > 0\), and we want to prove that \(\exists n \in \Naturals : \frac{n}{n + 1} > 1 - \varepsilon\)

\begin{align*}
    \frac{n}{n + 1} > 1 - \varepsilon \\ 
    \varepsilon >  1 - \frac{n}{n + 1} \\ 
    \varepsilon >  \frac{n + 1 - n}{n + 1} \\ 
    \varepsilon >  \frac{1}{n + 1} \\ 
    n + 1 >  \frac{1}{\varepsilon} \\ 
    n  >  \frac{1}{\varepsilon}  - 1 
\end{align*}

By the Archimedian principle we now that we can always find a bigger natural number such that \(n > \frac{1}{\varepsilon} - 1\)

Now we can reverse the steps in the inequality, and we will get our original inequality.

\QED

\subsubsection{Alternative Characterization of the Supremum}

Given a non-empty set \(A \subseteq \Reals\). The \(s \in Reals\) is only a supremum of \(A\) if 

\[
    (\nexists s \in A, s < x) \land (s' \in \Reals, s' < s \implies !\exists x \in A, x > s')
\]

\subsection{Properties of Suprema and Infima}

For non-empty sets \(A, B \subseteq \Reals^+\)

\begin{itemize}

    \item \(\sup AB = \sup A \cdot \sup B\)

    \item \(\inf AB = \inf A \cdot \inf B\)

    \item \(\sup (A + B) = \sup A + \sup B \)

    \item \(\inf (A + B) = \inf A + \inf B \)

    \item \(\sup (A / B) = \sup(A) / \inf(B)\)
     
    \item \(\sup (-A) = - \inf A\)

    \item \(\inf (-A) = - \sup A\)

\end{itemize}

For the sake of completeness we will prove one of these properties: 

\textbf{Proof:}

By definition \(\forall ab \in AB\) the following holds: 

\[
    ab \le \sup A \cdot \sup B \implies \sup AB \le \sup A \cdot \sup B
\]

Because \(\sup A\) and \(\sup B\) not necessarily belong to \(A\) or \(B\). With this, we already have the 
half of the proof. Now we need to prove that \(\sup AB \ge \sup A \cdot \sup B\). 

Start with 

\begin{align*}
    ab &\le \sup AB \\ 
    a &\le \frac{\sup AB}{b} 
\end{align*}

Therefore, \(\frac{\sup AB}{b}\) is an upper bound of \(A\). This means that: 

\[
    \sup A \le \frac{\sup AB}{b} \implies \sup A \cdot b \le \sup AB
\]

From this we can also derive that 

\[
    \sup A \cdot b \le \sup AB \implies b \le \frac{\sup AB}{\sup A}
\]

Thus, because \(\frac{\sup AB}{\sup A}\) is an upper bound of \(B\) we have that:

\[
    \sup B \le \frac{\sup AB}{\sup A} \implies \sup A \cdot \sup B \le \sup AB
\]

Combining both parts of the proof we have that:

\[
    \sup AB = \sup A \cdot \sup B
\]

\QED 

The other proofs can be proven using similar arguments.

\subsection{Limit and Accumulation Point}

\begin{itemize}

    \item A \emph{limit} of a sequence \((a_n)\) is the value the terms get arbitrarily close to as 
    \(n \to \infty\).

    \item An \emph{accumulation point} (or limit point) of a set \(A\) is a point \(x\) such that every 
    neighborhood of \(x\) contains infinitely many points of \(A\).

\end{itemize}

\textbf{Example:}

The sequence \(a_n = {(-1)}^n + \frac{1}{n}\) has two accumulation points: \(1\) and \(-1\).

\subsection{The Monotone Convergence Theorem}

Let \(a_n\) be a monotone sequence. Then \(a_n\) converges if and only if it is bounded. 

\textbf{Proof:} 

\(a_n\) converges; thus there exists a limit and therefore, the sequence is bounded. 

The sequence \(a_n\) is bounded and monotone. Therefore, there exist both infimum and supremum. We will prove the case for the supremum

\[
    a \ge a_i \forall a_i \in a_n \implies a - \varepsilon < a_i
\]

Suppose \(a\) is the limit then for all \(i > n_0, n_0 \in \Naturals\)

\begin{align*}
    |a_i - a| &< \varepsilon \\  
    |a - a_i| &< \varepsilon \\  
    |a - a_i| = a - a_i &< \varepsilon \\  
    a  - \varepsilon &< a_i 
\end{align*}

Therefore, the supremum is the limit.

\QED

\subsection{Monotony}

We define a real valued function \(f\) as \emph{monotone increasing/decreasing}

\[
    x < y \implies f(x) \le f(y)
\]
\[
    x < y \implies f(x) \ge f(y)
\]

We call it \emph{strictly monotone increasing or decreasing} if \(f(x) < f(y)\) or \(f(x) > f(y)\).

\subsection{Monotonicity by Difference and Quotient}

A is considered \emph{monotone} if either for all \(n \in \Naturals\) the following holds 

\[
    a_{n + 1} \ge a_{n} \text{ or } a_{n + 1} \le a_n
\]

\emph{Monotonicity by Difference:}

\begin{itemize}

    \item If \(a_{n+1} - a_n \ge 0\) for all \(n\), then the sequence is non-decreasing.

    \item If \(a_{n+1} - a_n < 0\), it is non-increasing.

\end{itemize}

\emph{Monotonicity by Quotient:} (Typically for positive sequences)

\begin{itemize}

    \item If \(\frac{a_{n+1}}{a_n} \ge 1\), then the sequence is non-decreasing.

    \item If \(\frac{a_{n+1}}{a_n} < 1\), it is non-increasing.

\end{itemize}

\subsection{Divergence}

A sequence \emph{diverges} if it does not converge. That is, there is no real number \(L\) such that:

If it diverges towards some infinity then 

\[
    \forall M \in \Reals \exists n,N \in \Naturals : |a_n| \ge |M| \forall n \ge N
\]

\begin{itemize}

    \item A sequence can diverge to \(\infty\) or \(-\infty\)

    \item A sequence can also oscillate without approaching any limit

\end{itemize}

\textbf{Example:}

The sequence \(a_n = {(-1)}^n\) diverges since it oscillates between \(1\) and \(-1\).

\subsection{Subsequences and Their Properties}

A \emph{subsequence} of a sequence \((a_n)\) is a sequence \((a_{n_k})\) where \((n_k)\) is a strictly 
increasing sequence of natural numbers.

\textbf{Properties:}

\begin{itemize}

    \item Every subsequence of a convergent sequence converges to the same limit.

    \item A sequence converges if and only if all of its subsequences converge to the same limit.

    \item A bounded sequence always has at least one convergent subsequence (Bolzano-Weierstraß theorem).

\end{itemize}

\subsubsection{Existence of the Accumulation Point as Limit}

A sequence \(\{x_n\}_{n = 1}^{\infty}\) has \(x_0\) as accumulation point if and only if there exists a subsequence 
which converges towards \(x_0\).

\textbf{Proof:}

Suppose that \(x_0\) is an accumulation point then \((x_0 - 1, x_0 + 1)\) contains a sequence member \(x_{n_0}, n_0 \in \Naturals\).
Let  

\[
    n_1 := n_0
\]

For each \(k \in \Naturals\) exists some \(N(k) \in \Naturals\) such that \(N(k) > N(k - 1)\)
and 

\[
    x_{N(k)} \in  (x_0 - \frac{1}{k}, x_0 + \frac{1}{k})
\]

Now we set 

\[
    n_k = N(k)
\]

For each subsequence \(\{x_{n_k}\}_{k = 1}^{\infty}\) the following holds 

\[
    |x_{n_k} - x_0 | \le \frac{1}{k}
\]

Therefore, the subsequence converges also towards \(x_0\).

Other way of the proof, if the sequence \(\{x_{n_k}\}_{k = 1}^{\infty}\) converges towards \(x_0\) then there exists a \(\delta > 0\) and \(K \in \Naturals\) 
such that 

\[
    x_{n_k} \in (x_0 - \delta, x_0 + \delta), \forall k \ge K
\]

Therefore, each neighborhood has infinite sequence members. 

\QED 

\subsubsection{Monotone Subsequence}

Every sequence \(a_n\) has monotone subsequence.

\textbf{Proof:}

Let \(a_n\) be a sequence and \(a_m\) be a peak if \(\forall a_i \in a_n, i > m, m, i \in \Naturals\) the following holds \(a_i \le a_m\). 

Now consider the case that \(a_n\) has infinitely many peaks. Let \(a_{n_k}\) be the sequence of the \(k\)-th peak. This gives us that 
each peak is greater or equal than the other, therefore we have monotone growing subsequence. If we define the peaks with \(a_i \ge a_m\) we also would 
get monotone sequence, but a decreasing instead.

For the case that there are only a finite number of peaks, let \(a_n\) be the last peak \(a_i \ge a_m\). If we can always find another \(a_{i + 1}\) such 
that \(a_{i + 1} \ge a_n\), therefore we can find monotone increasing subsequence. Similarly, the case for the decreasing case can be shown.

\QED 

\subsubsection{Convergence due to Subsequences}

A sequence \(\{a_n\}_{n = 1}^{\infty}\) converges to \(a\) if and only if each of its subsequences also 
converges to \(a\).

\textbf{Proof:}

Let \(a_{n_k}\) be a subsequence of \(a_n\). Let \(\varepsilon > 0\). 

\[
    \exists n_0 \in \Naturals, |a_n - a| < \varepsilon \forall n > n_0
\]

We want to show 

\[
    \exists n_1 \in \Naturals, |a_{n_k} - a| < \varepsilon \forall k > n_1
\]

with \(n_k \ge k\). 

Let \(n_1 = n_0\) then if \(k > n_1\), \(k > n_0\) and \(n_k \ge k > n_0\). Thus, for all \(k > n_1\), 
\(|a_{n_k} - a | < \varepsilon\).

For the other way of the proof: assume every subsequence of \(a_n\) converges to \(a\). \(a_n\) is itself a subsequence 
of thus, it converges to \(a\). 

\QED

\subsection{Proof that \(-1^n\) is divergent}

Let us assume that a limit exists then 

\[
    |-1^n - L| < \varepsilon \forall n \ge N 
\]

Let us choose \(\varepsilon = \frac{1}{2}\). 

Now our sequence bounces between -1 and 1 thus we can say that 

\[
    |-1 - L| < \frac{1}{2}
\]
\[
    |1 - L| < \frac{1}{2}
\]

Now let us use the triangle inequality a

\[
   2 = |-1 - L + 1 - L| \le |-1 + L| +  |1 - L| < 2\frac{1}{2} = 2
\]

This is a contradiction. Thus, such a limit can not exist

\QED 

\subsection{Bolzano-Weierstraß Theorem}

Every bounded sequence in \(\Reals\) has at least one convergent subsequence.

Equivalently, every bounded sequence of real numbers has at least one accumulation point.

\textbf{Proof:}

Let \(a_n\) be a bounded sequence, and let \(a_{n_k}\) be a monotone subsequence given by the monotone subsequence 
theorem. \(a_{n_k}\) is bounded because or original sequence is bounded.

Due to the monotone convergent theorem, we also know that the subsequence converges.
Therefore, our theorem is proven.

\QED

\subsection{Series}

A \emph{series} is the sum of the terms of a sequence:

\[
    \sum_{n=1}^{\infty} a_n
\]

We define the partial sums \(S_n = \sum_{k=1}^n a_k\). If the sequence \((S_n)\) converges to a limit \(S\), then the series is said to converge:

\[
    \sum_{n=1}^{\infty} a_n = S
\]

\subsection{Power Series}

A \emph{power series} is a series of the form:

\[
    \sum_{n=0}^{\infty} a_n {(x - x_0)}^n
\]

Where \(x_0\) is the center of the expansion. Power series converge within a radius \emph{R}:

\[
    R = \frac{1}{\limsup\limits_{n \to \infty} \sqrt[n]{|a_n|}}
\]

\subsection{Geometric Series}

There two types of \emph{geometric series}.

\emph{1. Finite geometric series:}

\[
    \sum_{n = 0}^{r - 1} aq^n = a \cdot \frac{1 - q^r}{1 - q} \quad \text{for } q \ne 1
\]

\emph{2. Infinite geometric series:}

\[
    \sum_{n = 0}^{\infty} aq^n = \frac{a}{1 - q} \quad \text{for } |q| < 1
\]

\subsection{Point-wise Convergence}

A sequence of functions \((f_n)\) converges \emph{point-wise} to a function \(f\) on a set \(A\) if:

\[
    \forall x \in A, \quad \lim_{n \to \infty} f_n(x) = f(x)
\]

Point-wise convergence does not preserve properties like continuity or differentiability.

\subsection{Uniform Convergence}

A sequence of functions \((f_n)\) converges \emph{uniformly} to \(f\) on \(A\) if:

\[
    \forall \varepsilon > 0, \exists n_0 \in \Naturals \text{ such that } \forall n \ge n_0, \forall x \in A, \quad |f_n(x) - f(x)| < \varepsilon
\]

\emph{Key Property:} Uniform convergence preserves continuity, integration, and differentiation under 
certain conditions.

\subsection{Cauchy Criterion for Series}

A series \(\sum a_n\) converges if and only if for every \(\varepsilon > 0\) there exists \(n_0\) 
such that:

\[
    \left| \sum_{k = m}^{n} a_k \right| < \varepsilon \quad \forall n > m \ge n_0
\]

\subsection{Interval Nesting and the Interval Nesting Theorem}

Let \((I_n)\) be a sequence of closed intervals:

\[
    I_n = [a_n, b_n] \quad \text{with } I_{n+1} \subseteq I_n, \text{ and } \lim_{n \to \infty} (b_n - a_n) = 0
\]

Then, the intersection contains exactly one point:

\[
    \bigcap_{n=1}^{\infty} I_n = \{x\}
\]

This is useful in proving the existence of limits, roots, and fixed points.

\subsection{Weierstraß Approximation Theorem}

The \emph{Weierstraß Approximation Theorem} states:

Every continuous function \(f: [a, b] \rightarrow \Reals\) can be uniformly approximated by a 
polynomial \(P(x)\), i.e., for every \(\varepsilon > 0\) there exists a polynomial \(P(x)\) such that:

\[
    |f(x) - P(x)| < \varepsilon \quad \forall x \in [a, b]
\]

This theorem is foundational in numerical analysis and approximation theory.

\subsection{Zero Sequence}

A sequence \((a_n)\) is called a \emph{null sequence} or \emph{zero sequence} if:

\[
    \lim_{n \to \infty} a_n = 0
\]

Every zero sequence is convergent (to 0), and plays an essential role in convergence proofs and 
epsilon-delta arguments.

More formally, a sequence \(\{a_n\}_{n = 1}^{\infty}\) of real numbers is called a zero sequence if and only if for all \(\varepsilon > 0\) there exists \(n_0\)
such that 

\[
    | a_{n_0} | < \varepsilon, \forall n \ge n_0 \in \Naturals
\]

Note that \(\{|a_n|\}_{n = 1}^{\infty}\) is only a zero sequence if \(\{a_n\}_{n = 1}^{\infty}\) is a zero sequence.

\textbf{Example:}

Is \(a_n = \frac{1}{n}\) a zero sequence?

Choose \(n_0 = \frac{1}{\varepsilon}\) then 

\[
    n \ge \frac{1}{\varepsilon} \implies \frac{1}{n} \le \varepsilon, \forall n \in \Naturals, n \ge n_0
\]

Thus, it is a zero sequence 

\subsection{Comparison Criteria for Sequences}

Given \(\{a_n\}_{n = 1}^{\infty}\) and \(\{b_n\}_{n = 1}^{\infty}\) with 

\[
    |b_n| \le |a_n|
\]

For all \(n \in \Naturals\) with \(n \ge n_0 \in \Naturals\). If  \(a_n \to 0, n \to \infty\) then  
\(b_n \to 0, n \to \infty\).

We also call \(a_n\) a majorant of \(b_n\).

\subsection{Properties of Zero Sequences}

Given the zero sequences \(\{a_n\}_{n = 1}^{\infty}, \{b_n\}_{n = 1}^{\infty}\)  and  the bounded sequence \(\{c\}_{n = 1}^{\infty}\) then 

\begin{itemize}

    \item \(\{a_n\}_{n = 1}^{\infty}\) is also bounded.

    \item \(\{\alpha a_n + \beta b_n\}_{n = 1}^{\infty}, \alpha, \beta \in \Reals\) is also a zero sequence.
    
    \item \(\{\sqrt{|a_n|}\}_{n = 1}^{\infty}\) is a zero sequence.

    \item \(\{a_n \cdot c_n\}_{n = 1}^{\infty}\) is a zero sequence.

\end{itemize}

\subsection{The Monotony Principle}

Every bounded monotonic sequence converges.

\textbf{Proof:}

Define \(a:= \sup\{a_n: n \in \Naturals\}\). We know that our sequence is bounded and in this case it has the 
property that \(a_n \le a\). 

We use the definition of convergence 

\begin{align*}
   |a_{n_0} - a | &< \varepsilon \\ 
   a_{n_0} &> a - \varepsilon
\end{align*}

Using the approximation property of the supremum we get 

\[
   a_n \ge a_{n_0} > a - \varepsilon, \forall n \ge n_0
\]

Therefore, we have for each \(\varepsilon > 0\) an \(n_0 \in \Naturals\)

\[
   a - \varepsilon \le a_{n_0} \le a  \forall n \ge n_0
\]

Thus, our theorem is true. 

\QED 

\begin{itemize}

    \item If \((a_n)\) is non-decreasing and bounded above, then \(\lim a_n\) exists and equals 
    \(\sup \{a_n\}\).

    \item If \((a_n)\) is non-increasing and bounded below, then \(\lim a_n = \inf \{a_n\}\).

\end{itemize}

To prove the convergence of a sequence via this principle we follow the next steps

\begin{enumerate}

    \item Prove the Monotonicity by induction

    \item Calculate the limit

    \item Prove the limitedness via induction

    \item Write the conclusion

\end{enumerate}

\textbf{Example:} 

\(a_{n + 1} = \sqrt{2a_n - 3} + 1\)

Let us assume that the series is decreasing or \(a_{n + 1} < a_{n}\)

\begin{align*}
    a_{n + 2} &< a_{n + 1} \\
    \sqrt{2a_{n + 1} -3} + 1 &< \sqrt{2a_{n} - 3} + 1 \\
    \sqrt{2a_{n + 1} -3} &< \sqrt{2a_{n} - 3} \\
    2a_{n + 1} - 3 &< 2a_{n} - 3 \\
    a_{n + 1} &< a_{n}
\end{align*}

\QED

Now let us calculated the limit

\[
    \lim_{n \rightarrow \infty} a_{n + 1} = \lim_{n \rightarrow \infty} \sqrt{2a_n - 3} + 1
\]

Because of the recursion we know that both \(a_{n + 1}\) and \(a_n\) have the same value, 
and we call it \(a\).

\[
    a = \sqrt{2a -3} +1
\]
\[
    a = 2
\]

We only have to prove the limitedness now:

For \(n = 0\) we have \(a_1 = 4 > 2\) then let us assume that the \(a\) is never going bellow 2.

\[
    a_{n + 1} = \sqrt{2a_n - 3} + 1 \ge \sqrt{2(2) - 3} + 1 = 2
\]

By setting \(a_n = 2\) we get the limit again

\QED

\subsection{Operations on Sequences}

\subsubsection{Sum of Sequences}

The sum of two sequences \((a_n)\) and \((b_n)\) is a new sequence \((c_n)\) where each term 
\(c_n\) is the sum of the corresponding terms of \((a_n)\) and \((b_n)\):

\[
    c_n = a_n + b_n, \quad \forall n \in \Naturals.
\]

If \(\lim_{n \to \infty} a_n = A\) and \(\lim_{n \to \infty} b_n = B\), then the limit of the sum sequence is:

\[
    \lim_{n \to \infty} (a_n + b_n) = A + B.
\]

\subsubsection{Multiplication of Sequences}

The product of two sequences \((a_n)\) and \((b_n)\) is a new sequence \((d_n)\) where each term \(d_n\) 
is the product of the corresponding terms of \((a_n)\) and \((b_n)\):

\[
    d_n = a_n \cdot b_n, \quad \forall n \in \Naturals.
\]

If \(\lim_{n \to \infty} a_n = A\) and \(\lim_{n \to \infty} b_n = B\), then the limit of the product sequence is:

\[
    \lim_{n \to \infty} (a_n \cdot b_n) = A \cdot B.
\]

\subsubsection{Absolute Value of a Sequence}

The absolute value of a sequence \((a_n)\) is a new sequence \((e_n)\) where each term \(e_n\) is the absolute value of the corresponding term of \((a_n)\):

\[
    e_n = |a_n|, \quad \forall n \in \Naturals.
\]

If \(\lim_{n \to \infty} a_n = A\), then the limit of the absolute value sequence is:

\[
    \lim_{n \to \infty} |a_n| = |A|.
\]

\subsubsection{Conjugate of a Complex Sequence}

If \((a_n)\) is a sequence of complex numbers, where \(a_n = x_n + i y_n\) with \(x_n, y_n \in \Reals\), then the conjugate of \((a_n)\) is a new sequence \((\overline{a_n})\) where each term \(\overline{a_n}\) is the complex conjugate of \(a_n\):

\[
    \overline{a_n} = x_n - i y_n, \quad \forall n \in \Naturals.
\]

If \(\lim_{n \to \infty} a_n = A = X + i Y\), then the limit of the conjugate sequence is:

\[
    \lim_{n \to \infty} \overline{a_n} = \overline{A} = X - i Y.
\]

\subsubsection{Complex Limit (Real and Imaginary Parts)}

For a sequence of complex numbers \((a_n)\) where \(a_n = x_n + i y_n\), the limit of the sequence 
\(\lim_{n \to \infty} a_n = A = X + i Y\) exists if and only if the limits of the real part sequence 
\((x_n)\) and the imaginary part sequence \((y_n)\) exist individually:

\[
    \lim_{n \to \infty} a_n = A \iff \left( \lim_{n \to \infty} \text{Re}(a_n) = \text{Re}(A) = X \quad \text{and} \quad \lim_{n \to \infty} \img(a_n) = \img(A) = Y \right).
\]

This means we can analyze the convergence of a complex sequence by examining the convergence of its real 
and imaginary parts separately.

\subsubsection{Asymptotic Equality}

Two sequences \({(a_n)}_{n \in \Naturals}\) and \({(b_n)}_{n \in \Naturals}\) are said to be 
asymptotically equal, denoted by \(a_n \sim b_n\), if

\[
    \lim_{n \to \infty} \frac{a_n}{b_n} = 1,
\]

provided that \(b_n \neq 0\) for all sufficiently large \(n\). Asymptotic equality implies that the sequences behave similarly as \(n\) approaches infinity.

\subsection{Boundness of a Function}

A real valued function \(f\) is \emph{bounded bellow} if 

\[
    \forall x \in \mathcal{D}(f) f(x) \ge m
\]

and \emph{bounded above} if 

\[
    \forall x \in \mathcal{D}(f) f(x) \le m
\]

\subsection{Inverse function due to Monotony}

Given a strictly monotonic function \(f\). Then \(f\) has an inverse.

\textbf{Proof:}

Given \(x_1 < x_2\) or \(x_1 > x_2\) then due to the monotony 

\[
    f(x_1) < f(x_2) \text{ or } f(x_1) > f(x_2)
\]

Thus, \(f(x_1) = f(x_2) \iff x_2 = x_1\)

\QED

\subsection{Domain Restriction}

Given \(f: A \to B\) and \(C \subsetneq A\) then 

\[
    g := f_{\mid C}: C \to B, x \mapsto f(x)
\]

\(f\) with \emph{restricted} domain. The case with \(A \subsetneq C\) will be the \emph{expansion}.