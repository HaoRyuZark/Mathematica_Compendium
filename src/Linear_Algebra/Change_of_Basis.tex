\newpage
\section{Changing between Basis}

The change of basis is a very important concept in linear algebra which allows us to change the way we describe vectors and linear transformations.
This is particularly useful when we want to express vectors in a different coordinate systems, or we want to apply a linear transformation, in an easy-to-work basis.
A good metaphor for this is to think of it as translating between different languages, where each basis is a different language. While keeping
in mind that from the perspective of a user of a different basis, the basis vectors are not different from the canonical basis.

\subsection{Understanding the change of basis}

Given a vector \(\vec{x} = \lambda_1 \vec{v}_1 + \cdots + \lambda_n \vec{v}_n\)
with \(\vec{v}_1, \dots, \vec{v}_n\) being the basis vectors, we can write \(\vec{x}\) in terms of its components \((x_1, \dots, x_n)^T\).

Now imagine having another basis \(\vec{b}_1, \dots, \vec{b}_n\) and the same vector \(\vec{x}\)
with all of its components. The key here is that we want to know how our original
vector is described in terms of other basis. More precisely what are its coordinates

So our vector \(\vec{x}\) is described:

\[
    \lambda_1 \vec{v}_1 + \cdots + \lambda_n \vec{v}_n = \vec{x} =  \mu_1 \vec{b}_1 + \cdots + \mu_n \vec{b}_n,
\]

in the corresponding bases. Note, that the vectors \(\vec{v}_i\) are written in the standard basis. And same goes for the vectors \(\vec{b}_i\).

Now let us write then as matrix vector multiplication

\[
    (\vec{v}_1, \dots, \vec{v}_ n)
    \begin{bmatrix} \lambda_1 \\ \vdots \\ \lambda_n \end{bmatrix}
    = \vec
    (\vec{b}_1, \dots, \vec{b}_ n)
    \begin{bmatrix} \mu_1 \\ \vdots \\ \mu_n \end{bmatrix}
\]

Now let us use the following notation for the basis and the coefficient vectors.

\[
    P_\beta {(\vec{x})}_\beta = \vec{x} = P_\gamma {(\vec{x})}_\gamma
\]

Here \(P_{\beta}\) is the matrix of the basis \(V\) vectors and \({(\vec{x})}_\beta\) the coefficients of the
vector described by that basis. The same goes for \(P_\gamma\) and \({(\vec{x})}_\gamma\).

Now that conversion of basis is just a matter of solving for our desired vector by multiplying
by the inverse of the corresponding basis matrix. We can also ignore the vector \(x\) in the middle
and just use the equality where we can solve for the vector in the desired basis.

\[
    P_\beta {(\vec{x})}_\beta = P_\gamma {(\vec{x})}_\gamma
\]


Now let us understand what really is happening in the step where we multiply by the inverse matrix.

\begin{align*}
    P_{\gamma}^{-1} P_\beta & = P_{\gamma}^{-1}(\vec{b}_1, \dots, \vec{b}_n)                \\
                            & = (P_{\gamma}^{-1}\vec{b}_1, \dots, P_{\gamma}^{-1}\vec{b}_n) \\
                            & = ({(\vec{b}_1)}_\gamma, \dots, {(\vec{b}_n)}_\gamma)
\end{align*}

When we start from some basis, our perspective is that our basis look like the standard basis. Given a matrix \(P_\beta\) which consist of our basis vectors
from the perspective of the 'real' standard basis, when we multiply a vector of coefficients in our basis with \(P_\beta\) we are going from our basis to the standard basis.
If we then apply \(P_{\beta}^{-1}\) this takes us back to our basis.

Knowing that, then if instead of  \(P_{\beta}^{-1}\) we apply the inverse matrix of another basis \(P_{\gamma}^{-1}\) then it will  translate our vector from the canonical basis
to the basis \(\gamma\). Which at the end is simply getting the coordinate of the basis vectors of \(\beta\) in the basis \(\gamma\).

\subsection{Coordinate mapping}

Let \( V \) be a \(\Field\)-vector space with a basis \( \beta = \{v_1, \ldots, v_n\} \).
Then there exists exactly one isomorphism

\[
    \varphi_\beta : \Field^n \to V
\]

such that

\[
    \varphi_\beta(e_i) = v_i, \quad \text{for } 1 \leq i \leq n.
\]

which is called the \emph{coordinate mapping} of \( V \) with respect to the basis \( \beta \).

\subsection{Coordinates with respect to a basis}

The isomorphism \( \varphi_\beta \) from the previous theorem is called the \emph{coordinate mapping},
and for \( v \in V \), we define

\[
    (\vec{v})_\beta := \varphi_\beta^{-1} (v) \in \Field^n
\]

as the \emph{coordinates of \( v \) with respect to \(\beta\)}.

\subsection{Translation of Coordinates}

We define the \emph{Translation} of a vector to another basis as:

\[
    T_{\beta}^{\gamma} = \varphi_{\beta}^{-1} \circ \varphi_\gamma
\]

where \(\varphi_\beta\) and \(\varphi_\gamma\) are the matrices made of the basis vector of the bases \(\beta\) and \(A\) with respect
to the standard basis, respectively.

\[
    \begin{tikzcd}
        & V & \\
        \Field^n \arrow[ur, "\varphi_\gamma"] \arrow[rr, "T_{\beta}^{\gamma} = \varphi_\beta^{-1} \circ \varphi_\gamma"'] & & \Field^n \arrow[ul, "\varphi_\beta"']
    \end{tikzcd}
\]

\subsection{Change of Basis Theorem}

Let \( v \in V \) be arbitrary, with \( (\vec{v})_\gamma = {(x_1, \dots, x_n)}^T \)
and \( (\vec{v})_\beta = {(y_1, \dots, y_n)}^T \).  Then the following holds:

\[
    (\vec{v})_\beta =  \varphi_\beta^{-1} \circ \varphi_\gamma (\vec{v})_\gamma
\]

In vector notation with the translation:

\[
    \begin{bmatrix}
        y_1    \\
        \vdots \\
        y_n
    \end{bmatrix}
    =
    T_\beta^A
    \begin{bmatrix}
        x_1    \\
        \vdots \\
        x_n
    \end{bmatrix}
\]

\subsection{Change of Basis in Linear Maps}

Let \( V \) and \( W \) be finitely generated \( \Field\)-vector spaces with
bases \(\gamma\) and \(\beta\), respectively, and let \( f \in \mathrm{Hom}(V, W) \).
Then we have

\[
    M_\beta^\gamma(f) = \varphi_\beta^{-1} \circ f \circ \varphi_\gamma
\]

Thus, \( M_\beta^\gamma(f) \) tells you to take vector in the basis \(\gamma\), translate it to the canonical basis,
apply the linear map \(f\) and then convert the result to the basis \(\beta\).

\[
    \begin{tikzcd}
        \Field^n \arrow[rrrr, "M_{\beta}^{\gamma}"] \arrow[rd, "\varphi_\gamma"] &                   &  &   & \Field^m \arrow[ld, "\varphi_\beta"'] \\
        & V \arrow[rr, "f"] &  & W &
    \end{tikzcd}
\]


\subsection{Transformations involving multiple bases}

Let \( V \) and \( W \) be finitely generated vector spaces with bases \(\gamma\) and \( \gamma' \)
for \( V \), and \(\beta\) and \( \beta' \) for \( W \), respectively.  Furthermore, let \( f: V \to W \) be
a linear map. Then the following holds:

\[
    M_{\beta'}^{\gamma'}(f) = T_{\beta'}^{\beta} \cdot M_{\beta}^{\gamma}(f) \cdot {\left( T_{\gamma'}^{\gamma} \right)}^{-1}
\]

More explicitly, we can write this as:

\begin{align*}
    M_{\beta'}^{\gamma'}(f) & = T_{\beta'}^{\beta} \cdot M_{\beta}^{\gamma}(f) \cdot {\left( T_{\gamma'}^{\gamma} \right)}^{-1}                                                                         \\
                            & = (\varphi_{\beta'}^{-1} \circ \varphi_{\beta}) \circ   (\varphi_{\beta}^{-1} \circ f \circ \varphi_{\gamma}) \circ ( \varphi_{\gamma'}^{-1} \circ \varphi_\gamma )^{-1}. \\
                            & = (\varphi_{\beta'}^{-1} \circ \varphi_{\beta}) \circ   (\varphi_{\beta}^{-1} \circ f \circ \varphi_{\gamma}) \circ ( \varphi_{\gamma}^{-1} \circ \varphi_{\gamma'}).
\end{align*}

We can visualize this as a commutative diagram where when take an inverse we reverse the direction of the arrows:

\[
    \begin{tikzcd}
        \Field^n \arrow[dd, "T_{\gamma'}^{\gamma}"] \arrow[rrrr, "M_{\beta}^{\gamma}"] \arrow[rd, "\varphi_\gamma"] &                   &  &   & \Field^m \arrow[dd, "T_{\beta'}^{\beta}"] \arrow[ld, "\varphi_\beta"'] \\
        & V \arrow[rr, "f"] &  & W &                                                       \\
        \Field^n \arrow[rrrr, "M_{\beta'}^{\gamma'}"] \arrow[ru, "\varphi_{\gamma'}"']                    &                   &  &   & \Field^m \arrow[lu, "\varphi_{\beta'}"]
    \end{tikzcd}
\]


