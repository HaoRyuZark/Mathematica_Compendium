\newpage
\section{Probability}

\subsection{Basics}

A probability experiment is considered ideal if and only the following properties: 

\begin{itemize}
   
    \item We know the possible outcomes. 

    \item It can be repeated multiple times under the same conditions.

    \item It will be executed under strict conditions.

\end{itemize}

\subsubsection{The Result Set}

The set of all possible results of an experiment is denoted as \(\Omega\) and its cardinality 
is the number of possible outcomes.

For experiments with \(\Omega\) as the result set of one repetition then we define 

\[
    \Omega = \Omega \times \cdots \times \Omega  
\]

As the \emph{result set} of the experiment.

Finally, each subset of \(\Omega\) is called an \emph{outcome}, each subset with 
only one element in it is called an \emph{elemental outcome} The set of all possible outcomes is 
\(\mathcal{P}(\Omega)\)

\subsubsection{Laplace Distribution and Experiment}

A \emph{Laplace distribution} is a probability experiment with finite outcomes where 
each elemental outcome has the same probability of occurring.

\[
    P(\omega) = \frac{\omega}{|\Omega|}
\]

Then an experiment with this property is considered a \emph{Laplace experiment}.

\[
    P(E) = \frac{E}{|\Omega|}
\]


\subsubsection{Expected Result}

Here \(p\) represents the probability of something and \(x\) the expected reward

\[
    E(x) = p_1 x_1 + \cdots + p_n x_n
\]

\subsection{Sigma Algebra}

Given a non-empty set \(\Omega\) and \(\mathcal{A} \subseteq \mathcal{P}(\Omaga)\) a set 
of subsets of \(Omega\). \(\mathcal{A}\) is a \(\sigma\)-Algebra if and only if 

\begin{enumerate}[I]
    
    \item \Omega \in \mathcal{A} \\ 

    \item A \int \mathcal{{A}} \implies A^c \mathcal{A} \\ 

    \item A_1, A_2, A_3, \dots \in \mathcal{A} \implies \bigcup_{n \in Naturals} A_n \in \mathcal{A}

\end{enumerate}

\subsubsection{The Power-set is a Sigma Algebra}

This proof is pretty straight forward. 

For the first axiom, we know that \(\Omega \in \mathcal{P}\). 

For the second axiom, if \(A\) is a subset of the power-set then \(\Omega \forwardslash A\) is also 
int the power-set.

And lastly, for a sequence of sets in the power-set their, union is also in the power-set, because the power-set 
contains all subsets of \(\Omega\).

\QED

\subsubsection{Properties of Sigma Algebras}

If \(\mathcal{A}\) is a sigma algebra then 

\begin{itemize}{label=\(-\)}
    
    \item \(\emptyset \in \mathcal{A}\) 

    \item \(A_1, A_2, \dots \in \mathcal{A} \implies \bigcap_{n \in \Naturals} A_n \in \mathcal{A}\)

    \item \(A, B \in \mathcal{A} \implies A \forwardslash B \in \mathcal{A}\)

\end{itemize}

\textbf{Proof:}

For the first, because \(\mathcal{A}\) is a subset of the power-set of \(\Omega\) and the empty set is 
always a subset of a collection, this is trivial. 

Given a number of sets in \(\mathcal{A}\), using the laws of De Morgan we get 

\[
    \bigcap_{n \in \Naturals} A_n = \bigcup A_{n}^{c}
\]

and we know that the complements are part of \(mathcal{A}\) by definition. 

For the last part, \(A \forwardslash B = A \cap B^c\), because \(B^c \in \mathcal{A}\) we can apply De Morgan 
\((A^c \cup (B^c)^c)^c = (A^c \cup B)^c\) Now because this is the union of two sets in the sigma algebra and we know by definition 
that their union if also in the set.

\QED

\subsection{Probability Measurement}

Given a non-empty set \(\Omega\) and \(\mathcal{A} \subseteq \mathcal{P}\) a sigma algebra. We define 
the function \(\mathbb{P}:\mathcal{A} \to \Reals\) as a \emph{probability measurement} if 

\begin{enumerate}[I]
    
    \item \(\forall A \in \mathcal{A}: \mathbb{P}(A) \ge 0\)

    \item \(\mathbb{P}(\Omega) = 1\) 

    \item \(A_n \in \mathcal{A}, n \in \Naturals \text{ disjunctive in pairs } \implies \mathbb{P}\left(\bigcup_{n \in \Naturals} A_n\right) = \sum_{n \in \Naturals} \mathbb{P}(A_n)\) 

\end{enumerate}

Also the triplet \(\Omega, \mathcal{A}, \mathbb{P}\) is called a \emph{probability space}.

\subsubsection{Probability space of the Power-set}

We want to prove that the probability space with the power-set of omega and \(\mathbb{P}(A) = \frac{|A|}{|\Omega|}\) is in fact a probability space 

\begin{itemize}
    
    \item \(\mathbb{P}(A) = \frac{|A|}{|\Omega|}\) is always greater or equal to zero.
    
    \item \(\mathbb{P}(\Omega) = \frac{|\Omega|}{|\Omega|} = 1\) 

    \item 

\end{itemize}

\subsection{Standard Deviation}

\[
    \sigma = \sqrt{ \frac{ {(\overline{x} - x_1)}^2 + \cdots + {(\overline{x} - x_n)}^2 }{ n } }
\]

\subsection{Binomial Distribution}

\textbf{Formulas:}

\begin{itemize}

    \item \emph{Probability: } \(P(X = k) = \binom{n}{k} p^k {(1 - p)}^{n - k}\)

    \item \emph{Expected Result: } \(E(X) = n * p\)

    \item \emph{Standard Deviation: } \(\sqrt{E(X)(1-p)}\)

    \item  \emph{Variance: } \(E(x)(1-p)\)

\end{itemize}

\subsubsection{Continuous Probability}

\[
    \sum_{i = P(X=k)}^{P(X=n) (P(X=i))}
\]

\textbf{Formulas: }

\begin{itemize}

    \item \(P(X = a) = P(X = a)\)

    \item \(P(X \le a) = P(X \le a)\)

    \item \(P(X < a) = P(X \le a - 1)\)

    \item \(P(X > a) = 1 - P(X \le a)\)

    \item \(P(X \ge a) = 1 - P(X \le - 1)\)

    \item \(P(a \le X \le b) = P(X \le b) - P(X \le a)\)

\end{itemize}

\subsubsection{Sigma Rules}

\begin{itemize}[label = \(-\)]

    \item \(P(\mu - \sigma \le x \mu + \sigma) \approx 68,3\%\)

    \item \(P(\mu - 2\sigma \le x \mu + 2\sigma) \approx 95,4\%\)

    \item \(P(\mu - 3\sigma \le x \mu + 3\sigma) \approx 99,7\%\)

\end{itemize}

\subsection{Normal Distribution}

\begin{itemize}
    
    \item \emph{Probability: } \(\frac{1}{\sqrt{2\pi \sigma^2} e^{\frac{1}{2} 
          {\left(\frac{x - u}{\sigma}\right)}^2}}\)
    
    \item \emph{Expected Result: } \(E(x) = np = \mu\)
    
    \item \emph{Variance: } \(Var(x) = E(X) (1-p)\)
    
    \item \emph{Standard Deviation: } \(\sqrt{Var(x)}\)

\end{itemize}

\subsection{Conditional Probability}

Probability of \(a\) under the condition \(b\).

\[
    P_b (a) = \frac{P(b \cap a)}{P(b)}
\]

\subsubsection{Formula for the Total Probability}

\[
    P(a) = P_b (a) P(b) + P_{\neg b}(a) P(\neg b)
\]

\subsection{Bayes Theorem}

\[
    P(a | b) = \frac{P(b | a) P(a)}{P(b)}
\]

\subsection{Hyper-geometric Distribution}

\[
    P(X = k) = \frac{\binom{M}{K} \binom{N - M}{n - K}}{\binom{N}{n}}
\]

\textbf{Nomenclature:}

\begin{itemize}

    \item \(N\): Total number of elements

    \item \(M\): Elements with the trait \(A\)

    \item \(N - M\): Elements without the trait \(A\)

    \item \(n = k\): Number to elements to take

\end{itemize}

\textbf{Formulas:}

\begin{itemize}

    \item \emph{Expected Results: } \(E(x) = n \frac{M}{N}\)

    \item \emph{Variance: } \(Var(X) = E(x)\left(1 - \frac{M}{N}\right) \left(\frac{N - n}{N - 1}\right)\)

\end{itemize}

\subsection{The Birthday Paradox}

This is a small question that says: What is the probability of at least two people having 
their birthday on the same day in a group of \(x\) persons.

\[
    P(x) = 1 - \prod_{n = 0}^{x} \frac{365 - n}{365}
\]

This formula gives us the probability of total minus all persons having it on different days. Which
what we are looking for.
