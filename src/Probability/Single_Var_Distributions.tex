\newpage
\section{Single Variable Distributions}

\subsection{Random Variables}

Given a probability space \((\Omega, \mathcal{A}, \Prob)\), we call a function \(f: \Omega \to \Reals\) \emph{measurable} if 
for all \(z \in \Reals\) the following applies 

\[
    f^{-1} ((- \infty, z ]) = \{\omega \in \Omega : f(\omega) \le z \} \in \mathcal{A}
\]

This measurable function \(X: \Omega \to \Reals\) is a \emph{random variable}.

Note that for discrete probability spaces \(\{\omega: X(\omega) \le z\} \subseteq \Omega \in \mathcal{P}\)

Also, it considered discrete if it has only a finite or an infinite countable number of values. 

Finally, we define the probability for random variables as

\[
    \Prob(X = k) := \Prob(\{X = k\})
\]

\subsubsection{Operations with Random Variables}

Given two R.V. \(X\),\(Y\) and some number \(\alpha \in \Reals\), then

\begin{itemize}

    \item \(X + Y\) 

    \item \(X - Y\) 

    \item \(X \cdot Y\) 

    \item \(\text{max}(X,Y)\)

    \item \(\text{min}(X,Y)\)

    \item \(\alpha X\) or \(\alpha Y\)

\end{itemize}

are also R.V.

\subsection{Indicator Function} 

Given \(A \subseteq \Omega\), we define the \emph{indicator function} as 

\[
    \text{ind}_A (\omega) = \begin{cases}
	1,& \text{ if }  \omega \in A \\ 
	0,& \text{ if }  \omega \notin A
    \end{cases}
\]

We also the get the following rules:

\begin{itemize}
    
    \item \(\text{ind}_\emptyset = 0\)
    
    \item \(\text{ind}_{A}^2 = \text{ind}_{A}\)
    
    \item \(\text{ind}_{A^c} = 1 - \text{ind}_A\)

    \item \(\text{ind}_{A \cap B} = \text{ind}_A \text{ind}_B \)

    \item \(\text{ind}_{A \cup B} = \text{ind}_A  + \text{ind}_B - \text{ind}_{A \cap B} \)

    \item \(\text{ind}_{A + B} = \text{ind}_A  + \text{ind}_B \)
    
\end{itemize}

\subsubsection{Indicator Sum}

Given the events \(A_1, \dots A_n \in \Omega\). We define the random variable 

\[
    X:= \sum_{j = 1}^{n} \text{ind}-{A_j}   
\]

as the \emph{indicator sum} or \emph{counting variable}. 

The realization of \(X\) gives us how much \(A_j\) have occurred. 

\[
    \{X = k\} = \sum_{T \subseteq \{1, \dots, n\}: |T| = k} \left( \bigcap_{j \in T} A_j \cap \bigcap_{j \notin T} A_{j}^{c} \right), k \in \{0, 1, \dots, n\}
\]

\subsection{Distributions}

Given our probability space and a R.V. \(X\). The probability measurement \(\Prob_X\) to 
\(\Reals\) defined by 

\[
    \Prob_X (A) := \Prob(\{\omega: X(w) \in A\}), \text{ for } A \subseteq \Reals
\]

is called as the \emph{distribution} of \(X\). Also we write \(\Prob(X \in A)\) as a abbreviation for
\(\Prob(\{\omega: X(w) \in A\}) \).

\subsection{Distribution Function}

Given a probability space, a probability variable and a distribution \(\Prob_X\) we define 
the function 

\[
    \mathbb{F}_X (x) = \Prob(X \le x) = \Prob(\{\omega: X(w) \le x\})
\]

as the \emph{distribution function}.

\subsubsection{Properties of Distribution Functions}

\begin{itemize}
    
    \item \(F_X\) is monotonic growing 

    \item It is right-sided continuous 

    \item \(\lim_{x \to - \infty} F_X (x) = 0\) and \(\lim_{x \to \infty} F_X = 1 \)

\end{itemize}

\subsection{Formulas for Distributions}

\begin{itemize}

    \item \(\Prob(X = a) = \Prob(X = a)\)

    \item \(\Prob(X \le a) = \Prob(X \le a)\)

    \item \(\Prob(X < a) = \Prob(X \le a - 1)\)

    \item \(\Prob(X > a) = 1 - \Prob(X \le a)\)

    \item \(\Prob(X \ge a) = 1 - \Prob(X \le - 1)\)

    \item \(\Prob(a \le X \le b) = \Prob(X \le b) - \Prob(X \le a)\)

\end{itemize}

\subsection{Uniform Distribution}

A random variable \(X \in \{1, 2, \dots, n\}\) with 
\(\Prob(X = i) = \frac{1}{n}\) for \(i = 1, \dots, n\) is uniformly distributed. 
The distribution \(\Prob_X\) is called the (discrete) \emph{uniform distribution}. Noted as 
\(\mathcal{U}(a, b)\)

\[
    \frac{1}{n}
\]

The expected value is given by 

\[
    \Expc(X) = \frac{n + 1}{2}
\]

and the standard deviation is given by

\[
    \sigma = \frac{n^2 - 1}{12}
\]

where \(a\) and \(b\) are the boundaries of our distribution.

\subsection{Bernoulli Distribution}

Distribution for binary events with only one trial, noted as \(\mathcal{B}(p)\)

\[
    \Prob(X = k) = p^k (1 - p)^{1 - k}, \quad k \in \{0, 1\}
\]

\subsection{Binomial Distribution}

From the Bernoulli distribution we can derive the \emph{binomial distribution} \(\text{Bino}(n, p)\)as having a number 
of consecutive independent Bernoulli experiments.

This distribution is for discrete binary experiments. Either an event occurs or it does not. 

\[
    \Prob(X = k) = \binom{n}{k} p^k {(1 - p)}^{n - k}
\]

With 

\[
    \Expc[X] = np
\]

\[
    \Var(X) = \Expc[X](1-p)
\]


We also get the standard deviation and our distribution function

\[
    \sigma = \sqrt{ \frac{ {(\overline{x} - x_1)}^2 + \cdots + {(\overline{x} - x_n)}^2 }{ n } }
\]

\[
    \mathbb{F}_X = \sum_{i = P(X=k)}^{P(X=n) (P(X=i))}
\]


If we let \(n \to \infty\) with \(np\) being not to small then the limit of this distribution becomes the normal distribution.

\subsection{Normal Distribution}

The \emph{normal distribution} \(\mathcal{N}(\mu, \sigma^2)\) is the limit of the \emph{binomial distribution} under certain conditions, and it is given by 

\[
    f(x) = \frac{1}{\sqrt{2\pi \sigma^2} e^{\frac{1}{2}{\left(\frac{x - u}{\sigma}\right)}^2}}
\]

It also has 

     
\[
    \Expc[X] = np = \mu
\]
    
\[
    \Var(X) = \Expc[X] (1-p)
\]

To compute its cumulative probability we need to use special tables, due to the fact that the function can not be analytically integrated. 
To get a specific we use tables which pre-calculated values computed numerically using the so called \(\Phi\) function. 
This function is used in the following manner:

We plug the values in the expression, our expected value and the standard deviation 

\[
    Z = \frac{X - \mu}{\sigma}
\]

\(\Phi(Z)\) you use the portion before the comma as the row and after the comma as the column to read the value from.


\subsubsection{Standard Normal Distribution}

The \emph{standard} normal distribution has the parameters \(\mu = 0\) and \(\sigma^2 = \Var = 1\). 

To transform a normal distributed random variable \(X\) you can define a new random variable 

\[
    Z = \frac{X - \mu}{\sigma}
\]

\textbf{Example:}

Given \(X \sim N(10, 4)\). What is \(\Prob(8 \le X \le 12)\)?

We define \(Z = \frac{X - 10}{2}\). Then we get 

\[
    \Prob(8 \le X \le 12) = \Prob\left(\frac{8 - 10}{2} \le Z \le \frac{12 - 10}{2}\right) = \Prob(-1 \le Z \le 1)
\]

Using the standard normal distribution table we get

\[
    \Prob(-1 \le Z \le 1) = \mathbb{F}_Z(1) - \mathbb{F}_Z(-1) = 0.8413 - 0.1587 = 0.6826
\]

\subsection{Geometric Distribution}

A random variable \(X \in \Naturals_0\) with 
\(\Prob(X = n) = p(1 - p)^n\) for some \(p \in (0, 1)\) and \(n \in \Naturals_0\) 
is geometrically distributed. The distribution \(\Prob_X\) is called the \emph{geometric distribution}.

Similar to the binomial distribution, the \emph{geometric} \(\mathcal{G}(n, p)\) distribution is used for an experiment with two 
outcomes, and we want to know the probability of \(k - 1\) non-successes until a success happens  

\[
    \Prob(X = k) = (1 - p)^{k - 1}p
\]

We also get

\[
    \Expc[X] = \mu = \frac{1 - p}{p}
\]

\[
    \Var = \frac{1 - p}{p^2}
\]

and 

\[
    \sigma = \sqrt{\Var(X)}
\]

\subsection{Poisson Distribution}

A random variable \(X \in \Naturals_0\) with 

\[
    \Prob(X = n) = \frac{\lambda^n}{n!} e^{-\lambda}, \quad \text{ for some } \lambda > 0,
\] 

We also define the distribution function 

\[
    \mathbb{F}_X(n) = \sum_{i = 0}^{n} \frac{\lambda^i}{i!} i^{-\lambda}
\]

is Poisson distributed. The distribution \(\Prob_X\) is called the \emph{Poisson distribution} \(\text{Poi}(\lambda)\)
In simple words, it is the number of events x, in a specific interval. This is 
a limit of the binomial distribution for large \(n\) and small \(p\).

We also get our expected result and variance 

\[
    \Expc[X] = \lambda = np
\]

and 

\[
    \Var(X) = \lambda
\]

The derivation is the following, let \(\lambda = np\)

\begin{align*}
    \lim_{n \to \infty} &\binom{n}{k} p^k (1 - p)^{n - k} \\ 
                        &= \frac{n!}{k!(n - k)!} \left(\frac{\lambda}{n}\right)^k \left(1 - \frac{\lambda}{n}\right)^{n - k} \\ 
                        &= \frac{n(n-1)\dots(n - k + 1)}{k!} \left(\frac{\lambda}{n}\right)^k \left(1 - \frac{\lambda}{n}\right)^{n - k} \\ 
                        &= \frac{n(n-1)\dots(n - k + 1)}{k!} \frac{\lambda^k}{n^k} \left(1 - \frac{\lambda}{n}\right)^{n - k} \\ 
                        &= \frac{\lambda^k}{k!} \frac{n(n-1)\dots(n - k + 1)}{n^k} \left(1 - \frac{\lambda}{n}\right)^{n} \left(1 - \frac{\lambda}{n}\right)^{-k}  \\ 
                        &= \frac{\lambda^k}{k!} \cdot 1 \cdot e^{-\lambda} \cdot 1 \\ 
                        &= \frac{\lambda^k}{k!} \cdot e^{-\lambda} 
\end{align*}

\subsection{Hyper-geometric Distribution}

Similar to the binomial distribution, but we keep track of the changes after each choice. In other words, 
binomial distribution without repetition. We notate this as \(\text{HG}(M, N, n)\).

\[
    \Prob(X = k) = \frac{\binom{M}{k} \binom{N - M}{n - k}}{\binom{N}{n}}
\]

\textbf{Nomenclature:}

\begin{itemize}

    \item \(N\): Total number of elements

    \item \(M\): Elements with the trait \(A\)

    \item \(N - M\): Elements without the trait \(A\)

    \item \(k\): Number to elements to take

    \item \(n\): Number of iterations

\end{itemize}

Each part of the formula has a different meaning. \(\binom{N}{n}\) represents the total number of ways to choose the elements from the total.
\(\binom{M}{k}\) gives us the ways of choose \(k\) elements with the trait from its total \(M\) and finally, \(\binom{N - M}{n - k}\) represents the remaining ways of choosing 
elements we are not interested in.

We also get 

\[
    \Expc[X] = n \frac{M}{N}
\]

\[
    \Var(X) = \Expc[X]\left(1 - \frac{M}{N}\right) \left(\frac{N - n}{N - 1}\right)
\]

\subsection{The Expected Value for Discrete Random Variables}

Given \(\Omega, \mathcal{A}, \Prob\), a probability space and \(X\) a discrete random variable. We 
define the \emph{expected result} as 

\[
    \Expc(X) = \sum_{x \in X(\Omega)} x \Prob(X = x)
\]

which exists only if 

\[
    \sum_{x \in X(\Omega)} |x| \Prob(X = x) < \infty
\]

Where \(x\) is an event \(\Prob(X = x)\) its respective probability. It represents the mean of the random variable.

\subsubsection{Transformation of the  Expected Value}

Given \(u: X(\Omega) \to \Reals\) where \(\sum_{x \in X(\Omega)} |u(x)|p(x) < \infty\) then 

\[
    \Expc[u(X)] = \sum_{x \in X(\Omega)} u(x)\Prob(X = x)
\] 

This represents the expectation of the function.

\subsection{Triangle Inequality for  Expected Values}

\[
    |\Expc[X]| \le \Expc[|X|]
\]

\textbf{Proof:}

\begin{align*}	
    |\Expc[X]| &= \left| \sum_{x \in X(\Omega)} x \Prob(X = x) \right| \le \sum_{x \in X(\Omega)} |x \Prob(X = x)| \\ 
		    &= \sum_{x \in X(\Omega)} |x| \Prob(X = x) = \Expc [|X|]
\end{align*}

\QED

\subsubsection{Properties of  Expected Values}

Given two random variables \(X\) and \(Y\), if both have an expected results then 

\begin{itemize}
	
    \item \(\Expc[\alpha X] = \alpha \Expc[X]\)

    \item \(\Expc[X + Y] = \Expc[X] + \Expc[Y]\)

    \item \(\Expc[b] = b\)
    
    \item \(X \le Y = \Expc[X] \le \Expc[Y]\)

\end{itemize}

\subsection{Variance}

Given a random variable \(X\) for which \(\Expc[(X - \Expc)^2]\) exists. The we define 
the \emph{variance} of \(X\) as 

\[
    \Var(X) = \Expc[(X - \Expc)^2] = \sum_{x \in X} (x -  \Expc^2)\Prob(X = x)
\]

And its root is the \emph{standard deviation}.

\subsubsection{Properties of the Variance}

Let \( X \) be a (discrete) random variable for which the variance exists.  
Then the following hold:

\begin{itemize}

    \item \(\Var(aX + b) = a^2 \, \Var(X)\), for \( a, b \in \Reals \)
    
    \item \(\Var(X) = \Expc[X^2] - (\Expc[X])^2\)
    
    \item For \( a \in \Reals \), we have  \(\Expc[(X - a)^2] = \Var(X) + (\Expc[X] - a)^2\),  
    and in particular, \(\Expc[(X - a)^2] \ge \Var(X)\).  
    Equality holds if and only if \( a = \Expc[X] \).

\end{itemize}

\textbf{Example:}

Given \(\Expc(X) = 1.2\) and \(\Prob(X = 0) = 0.16, \quad \Prob(X = 1) = 0.48, \Prob(X = 2) = 0.36\). 

\[
    \Expc[X^2] =  0^2 (0.16) + 1^2(0.48) + 2^2(0.36) = 1.92
\]

\[
    \Var(X) = \Expc[(X - \Expc)^2] = (0 - 1.2)^2 (0.16) + (1 - 1.2)^2(0.48) + (2 - 1.2)^2(0.36)
\]

\subsection{Moments}

For a random variable \(X\), we define \(k\). \emph{moment} as \(\Expc[X^k]\)

\subsubsection{Markov Inequality}

Given a random variable \(X\), \(a \in \Reals\) and \(h: D \to [0, \infty)\) a monotonic growing 
function with the properties \(h(a) > 0\) and \(X(\Omega) \subseteq D\) then 

\[
    \Prob(X \ge a) \le \frac{\Expc[h(X)]}{h(a)}
\]

Simpler, 

\[
    \Prob(X \ge a) \le \frac{\Expc[X]}{a}
\]

There is a special case for \(Y = |X|, a > 0\) and \(h(x) = x\) 

\[    
    \Prob(X \ge a) \le \frac{\Expc[h(X)]}{a}
\]

\subsubsection{Chebychev Inequality}

Given a random variable \(X\) with a variance and \(a > 0\) then 

\[
    \Prob(|X - \Expc[X]| \ge a) \le \frac{\Var(X)}{a^2}
\]

This states that the probability of \(X\) is at least \(a\) away of its mean can not be too big.

\subsection{Probability Density}

A Lebesgue-integrable function \( f : \Reals \to [0, \infty) \) is called the (probability)
\emph{density} or \emph{density function} of the random variable \( X \) or of the
distribution \( \Prob_X \) if, for all \( a, b \in \Reals \) with \( a \le b \), the following holds:

\[
    \Prob(a < X \le b) = \Prob_X((a, b]) = \int_a^b f(x)\,dx.
\]

Distributions that possess a probability density are called \emph{continuous distributions}.

\subsubsection{Properties of Continuous Distributions}

\begin{itemize}
	
    \item \(\mathbb{F}_X \) is continuous at \( x \) if and only if \( \Prob(X = x) = 0 \).

    \item 
	\[
	    \int_{-\infty}^{\infty} f_X(x)\,dx 
	    = \mathbb{F}_X(\infty) 
	    = \lim_{x \to \infty} P(X \le x) 
	    = 1.
	\]

    \item  If \( X \) is a continuous random variable, then \( F_X \) is continuous.

\end{itemize}

\subsubsection{How to Test if a Function words as a Density}

To test if given a function it can be used as a density functions we test:

\begin{itemize}
	
    \item \(f(x) \ge 0 \forall x \in \Reals \)

    \item \(\int_{-\infty}^{\infty} f(x) dx = 1\)

\end{itemize}

\subsubsection{Zero Property}

Given a continuous random variable \(X\) then 

For \(a, b \in \Reals\)

\[
    \Prob(a \le X \le b ) = F_X (b) - F_X (a) = \int_{a}^{b} f_X(x)dx = \Prob(a < X \le b)
\]

Also \(A \in \mathcal{B}(\Reals): \Prob(X \in A) = \int_A f_X (x)dx\)

And \(A \in \mathcal{B}(\Reals) \text{ (discrete) }: A = \{a_i\}_{i \in I}, I \in \Naturals :\) 

\[
    \Prob(X \in A) = \sum_{i \in I} \Prob(X = a_i) = 0
\]

\subsection{Expected Value for Continuous Random Variables}

Given a continuous random variable \(X\) with a density \(f_X\). The \emph{expected value}
of \(X\) exists if \(\int |x|f_X(x)dx , \infty\) In that case we define it as 

\[
    \Expc[X] = \int x f_X (x)dx 
\]

We also get all of its properties like for the discrete case.

\subsubsection{Transformation Lemma}

Given a continuous random variable \(X\) with a density \(f\) and a measurable function \(u: \Reals \to \Reals\) 
with \(\int |u(x)|f(x)dx < \infty\) then the following applies 

\[
    \Expc[u(X)] = \int u(x) f(x) dx
\]

\subsubsection{Continuous Uniform Distribution}

A random variable \(X \in [0,1]\) with 

\[
    \Prob (X \le x) \begin{cases}
	0 &, \text{ if } x < 0 \\
	x &, \text{ if } x \in [0,1] \\
	1 &, \text{ if } x > 1 \\
    \end{cases}
\]

is considered \emph{continuous equally distributed}. The distribution function 
\(\Prob_X\) is called \emph{continuous uniform distribution}. Generalized 

\[
    f(x) = \frac{1}{b  - a}
\]

And 

\[
    \Prob (X \le x) = \frac{x - a}{b - a}, x \in [a, b]
\]

with 

\[
    \Expc[X] =  \frac{a + b}{2}
\]
    
\[
    \Var(X) = \frac{(b - a)^2}{12}
\]

\subsection{Exponential Distribution}

We define the \emph{exponential distribution} \(\mathcal{E}(\lambda)\)as a real defined random variable, used mostly 
for the duration of time intervals.

\[
    f(n) = \begin{cases}
	\lambda e^{- \lambda n} &, n \ge 0 \\ 
	0 &, \text{ else }
    \end{cases} 
\] 

Where \(lambda\) our \emph{rate} parameter. 

\[
    \lambda = \frac{1}{\text{avarage}}
\]

We also define the distribution function 

\[
    \mathbb{F}_X(X = n) = \int_{- \infty}^{n} \Prob(X = n) = \begin{cases}
	1 - e^{- \lambda n} &, n \ge 0 \\ 
	0 &, \text{ else }
    \end{cases} 
\]

We also have 

     
\[
    \Expc(X) = \frac{1}{\lambda}
\]
    
\[
    \Var(X) = \frac{1}{\lambda^2}
\]
    

\subsubsection{Memory-less Property of the Exponential Distribution}

This distribution is \emph{memory-less}. This means that the future probabilities of an event are independent 
of the previous ones. 


\[
    \Prob (X \ge x + y \mid X > y) = \Prob(X \ge x)
\]

\subsubsection{The Connection between the Exponential Distribution and the Poisson Process}

A neat connection between these two concepts is that given an exponential distribution 
over some time \(t\) then the number of events which occurred during that interval is given by a Poisson distribution \(\mathrm{Poi}(\lambda t)\) 

\textbf{Example:}

Emails com at a rate of 5 per minute (\(\lambda = 5\)). What is the probability of waiting \(t\) until the next email?

The probability of getting an email after \(t\) waiting is given by the following exponential distribution

\[
    \Prob(T > t) = e^{-5}t
\]

What is the probability of getting no emails in the next \(t\) minutes?

This is given by the following Poisson process 

\[
    \Prob(k = 0) = \frac{5^0 e^{-5t}}{0!} = e^{-5t}
\]

\subsection{Gamma Distribution}

This distribution comes directly from the connection between the exponential distribution and the Poisson process.
Given events \(w_0, \dots, w_n\) with an exponential distribution. The \emph{gamma} distribution gives us the waiting time 
for the \(r-th\) event. 

\[
    T_r = \sum_{k = 0}^{r} w_k 
\]

We denote this as \(T_r \sim \mathrm{gamma}(r, \lambda)\). The probability density function is given by 

\[
    \Prob(T_r > t) = \Prob(N_t \ge r - 1) = \sum_{k = 0}^{r - 1} \frac{e^{-\lambda t}(\lambda t)^k}{k!} = \cdots = e^{-\lambda t}\frac{\lambda^r t^{r - 1}}{(r - 1)!}
\]

with \(N_t\) is the number of Poisson events in \(t\).

\subsection{Chi-Square Distribution}

The square of the \emph{normal distribution} is called the 
\emph{Chi-Square Distribution} noted as \(\mathcal{N}(a\mu + b, a^2 \sigma^2)\). Given a random variable \(X\) with density 

\[
    f(x) = \frac{1}{2^{\frac{n}{2}} \Gamma \left(\frac{n}{2}\right)} x^{\frac{n}{2 - 1}}e^{\frac{-x}{2}}
\]

We also have 

\[
    \Expc[X] = n
\]
    
\[
    \Var(X) = \Expc[X] 2n
\]

The probability density function is reached by taking the cumulative density function of the normal distribution which is 
an Integral, square it, and then we take its derivative.

\subsection{Transformation Theorem for Densities}

Given a random variable \(X\) with values in the open interval \(I \subseteq \Reals\) and the density \(f_X\). If 
\(j \subseteq \Reals\) is an open interval and \(u: I \to J\) is a diffeomorphism then has \(Y = u(X)\) the density 

\[
    f_Y (y) = f_X(u^{-1}(y)) | (u^{-1})'(y)|
\]

For \(y \in J\) and \(f_Y(y) = 0\) for \(y \in \Reals \setminus J\).

\subsection{Quantile}

Let \( X \) be a random variable with distribution \( F \).
For \( p \in (0, 1) \), a value \( q_p \) is called a \emph{p-quantile} of \( X \) (or of \( F \)) if:

\[
    \Prob(X \le q_p) \ge p \text{ and }\Prob(q_p \le X) \ge 1 - p,
\]

or equivalently,

\[
    F(q_p) \ge p \text{ and } \lim_{x \nearrow q_p} F(x) \le p.
\]

In general, the \( p \)-quantile is not unique.
If \( F \) is strictly increasing and continuous, then \( q_p \) is unique.
If \( q_p \) is not unique, we can make it “unique” by defining the smallest quantile as

\[
    F^{-1}(p) = \inf \{ x \in \Reals : F(x) \ge p \}.
\]

\subsection{The Moment Generating Function}

The \(n-th\)\emph{moment} of a distribution are given by \(\Expc[X^n]\). We also 
know that the first moment is the mean and the variance is closely related to the second moment.
The moments \emph{uniquely} determine the distribution.

The \emph{moment generating function} is defined as 

\[
    M(t) = 
    \begin{cases}
        \sum_{x} e^{tx} \Prob(X = x) & \text{ if } X \text{ discrete} \\
        \int_{-\infty}^{\infty} e^{tx} \Prob(X = x) dx & \text{ if } X \text{ continuous}
    \end{cases}
\]

\(M(t)\) uniquely determines the cumulative probability distribution of \(\Prob(X = x)\)

\subsubsection{Derivative of the Moment Generating Function}

The \(n-th\) derivative of the \emph{moment generating function} has the following property 

\[
    M^{n}(0) = \Expc[X^n]
\]

\textbf{Proof (Informal):}

We will handle only the continuous case, but the same holds for the discrete case 

\[
    \frac{d}{dt} \int_{-\infty}^{\infty} e^{tx} \Prob(X = x) dx  = \int_{-\infty}^{\infty} xe^{tx} \Prob(X = x) dx
\]

\[
    \frac{d}{dt} \int_{-\infty}^{\infty} xe^{tx} \Prob(X = x) dx  = \int_{-\infty}^{\infty} x^2 e^{tx} \Prob(X = x) dx
\]

And the pattern repeats. This is just given us the definition of each of the moments. 

\QED

\subsubsection{The Additive Property of the Moment Generating Function}

Let \(X_1, X_2, \dots, X_n\) be random variables with their corresponding moment generating functions.
Let \(Z = \sum_i X_i\) then 

\[
    M_Z (t) = \prod_{i} M_{X_i}(t)
\]


