\newpage
\section{Single Variable Distributions}

\subsection{Random Variables}

Given a probability space \((\Omega, \mathcal{A}, \Prob)\), we call a function \(f: \Omega \to \Reals\) \emph{measurable} if 
for all \(z \in \Reals\) the following applies 

\[
    f^{-1} ((- \infty, z ]) = \{\omega \in \Omega : f(\omega) \le z \} \in \mathcal{A}
\]

This measurable function \(X: \Omega \to \Reals\) is a \emph{random variable}.

Note that for discrete probability spaces \(\{\omega: X(\omega) \le z\} \subseteq \Omega \in \mathcal{P}\)

Also, it considered discrete if it has only a finite or an infinite countable number of values. 

Finally, we define the probability for random variables as

\[
    \Prob(X = k) := \Prob(\{X = k\})
\]

\subsubsection{Operations with Random Variables}

Given two R.V. \(X\),\(Y\) and some number \(\alpha \in \Reals\), then

\begin{itemize}

    \item \(X + Y\) 

    \item \(X - Y\) 

    \item \(X \cdot Y\) 

    \item \(\text{max}(X,Y)\)

    \item \(\text{min}(X,Y)\)

    \item \(\alpha X\) or \(\alpha Y\)

\end{itemize}

are also R.V.

\subsection{Indicator Function} 

Given \(A \subseteq \Omega\), we define the \emph{indicator function} as 

\[
    \text{ind}_A (\omega) = \begin{cases}
	1,& \text{ if }  \omega \in A \\ 
	0,& \text{ if }  \omega \notin A
    \end{cases}
\]

We also the get the following rules:

\begin{itemize}
    
    \item \(\text{ind}_\emptyset = 0\)
    
    \item \(\text{ind}_{A}^2 = \text{ind}_{A}\)
    
    \item \(\text{ind}_{A^c} = 1 - \text{ind}_A\)

    \item \(\text{ind}_{A \cap B} = \text{ind}_A \text{ind}_B \)

    \item \(\text{ind}_{A \cup B} = \text{ind}_A  + \text{ind}_B - \text{ind}_{A \cap B} \)

    \item \(\text{ind}_{A + B} = \text{ind}_A  + \text{ind}_B \)
    
\end{itemize}

\subsubsection{Indicator Sum}

Given the events \(A_1, \dots A_n \in \Omega\). We define the random variable 

\[
    X:= \sum_{j = 1}^{n} \text{ind}-{A_j}   
\]

as the \emph{indicator sum} or \emph{counting variable}. 

The realization of \(X\) gives us how much \(A_j\) have occurred. 

\[
    \{X = k\} = \sum_{T \subseteq \{1, \dots, n\}: |T| = k} \left( \bigcap_{j \in T} A_j \cap \bigcap_{j \notin T} A_{j}^{c} \right), k \in \{0, 1, \dots, n\}
\]

\subsection{Distributions}

Given our probability space and a R.V. \(X\). The probability measurement \(\Prob_X\) to 
\(\Reals\) defined by 

\[
    \Prob_X (A) := \Prob(\{\omega: X(w) \in A\}), \text{ for } A \subseteq \Reals
\]

is called as the \emph{distribution} of \(X\). Also we write \(\Prob(X \in A)\) as a abbreviation for
\(\Prob(\{\omega: X(w) \in A\}) \).

\subsection{Distribution Function}

Given a probability space, a probability variable and a distribution \(\Prob_X\) we define 
the function 

\[
    \mathbb{F}_X (x) = \Prob(X \le x) = \Prob(\{\omega: X(w) \le x\})
\]

as the \emph{distribution function}.

\subsubsection{Properties of Distribution Functions}

\begin{itemize}
    
    \item \(F_X\) is monotonic growing 

    \item It is right-sided continuous 

    \item \(\lim_{x \to - \infty} F_X (x) = 0\) and \(\lim_{x \to \infty} F_X = 1 \)

\end{itemize}

\subsection{Formulas for Distributions}

\begin{itemize}

    \item \(\Prob(X = a) = \Prob(X = a)\)

    \item \(\Prob(X \le a) = \Prob(X \le a)\)

    \item \(\Prob(X < a) = \Prob(X \le a - 1)\)

    \item \(\Prob(X > a) = 1 - \Prob(X \le a)\)

    \item \(\Prob(X \ge a) = 1 - \Prob(X \le - 1)\)

    \item \(\Prob(a \le X \le b) = \Prob(X \le b) - \Prob(X \le a)\)

\end{itemize}

\subsection{Uniform Distribution}

A random variable \(X \in \{1, 2, \dots, n\}\) with 
\(\Prob(X = i) = \frac{1}{n}\) for \(i = 1, \dots, n\) is uniformly distributed. 
The distribution \(\Prob_X\) is called the (discrete) \emph{uniform distribution}. Noted as 
\(\mathcal{U}(a, b)\)

\[
    \frac{1}{n}
\]

The expected value is given by 

\[
    \Expc(X) = \frac{n + 1}{2}
\]

and the standard deviation is given by

\[
    \sigma = \frac{n^2 - 1}{12}
\]

where \(a\) and \(b\) are the boundaries of our distribution.

\subsection{Bernoulli Distribution}

Distribution for binary events with only one trial, noted as \(\mathcal{B}(p)\)

\[
    \Prob(X = k) = p^k (1 - p)^{1 - k}, \quad k \in \{0, 1\}
\]

\subsection{Binomial Distribution}

From the Bernoulli distribution we can derive the \emph{binomial distribution} \(\text{Bino}(n, p)\)as having a number 
of consecutive independent Bernoulli experiments.

This distribution is for discrete binary experiments. Either an event occurs or it does not. 

\[
    \Prob(X = k) = \binom{n}{k} p^k {(1 - p)}^{n - k}
\]

With 

\[
    \Expc[X] = np
\]

\[
    \Var(X) = \Expc(x)(1-p)
\]


We also get the standard deviation and our distribution function

\[
    \sigma = \sqrt{ \frac{ {(\overline{x} - x_1)}^2 + \cdots + {(\overline{x} - x_n)}^2 }{ n } }
\]

\[
    \mathbb{F}_X = \sum_{i = P(X=k)}^{P(X=n) (P(X=i))}
\]

Sigma rules:

\begin{itemize}

    \item \(\Prob(\mu - \sigma \le x \mu + \sigma) \approx 68,3\%\)

    \item \(\Prob(\mu - 2\sigma \le x \mu + 2\sigma) \approx 95,4\%\)

    \item \(\Prob(\mu - 3\sigma \le x \mu + 3\sigma) \approx 99,7\%\)

\end{itemize}

\subsection{Normal Distribution}

The \emph{normal distribution} \(\mathcal{N}(\mu, \sigma)\) is the limit of the \emph{binomial distribution} and it is given by 

\[
    f(x) = \frac{1}{\sqrt{2\pi \sigma^2} e^{\frac{1}{2}{\left(\frac{x - u}{\sigma}\right)}^2}}
\]

It also has 

     
\[
    \Expc[X] = np = \mu
\]
    
\[
    \Var(X) = \Expc[X] (1-p)
\]

To compute its cumulative probability we need to use special tables, due to the fact that the function can not be analytically integrated. 
To get an specific we use tables which pre-calculated values computed numerically using the so called \(\Phi\) function. 
This functions is used in the following manner:

We plug the values in the expression, our expected value and the standard deviation 

\[
    Z = \frac{X - \mu}{\sigma}
\]

\(\Phi(Z)\) you use the portion before the comma as the row and after the comma as the column to read the value from.


\subsubsection{Standard Normal Distribution}

The \emph{standard} normal distribution has the parameters \(\mu = 0\) and \(\sigma^2 = \Var = 1\). 

To transform a normal distributed random variable \(X\) you can define a new random variable 

\[
    Z = \frac{X - \mu}{\sigma}
\]

\textbf{Example:}

Given \(X \sim N(10, 4)\). What is \(\Prob(8 \le X \le 12)\)?

We define \(Z = \frac{X - 10}{2}\). Then we get 

\[
    \Prob(8 \le X \le 12) = \Prob\left(\frac{8 - 10}{2} \le Z \le \frac{12 - 10}{2}\right) = \Prob(-1 \le Z \le 1)
\]

Using the standard normal distribution table we get

\[
    \Prob(-1 \le Z \le 1) = \mathbb{F}_Z(1) - \mathbb{F}_Z(-1) = 0.8413 - 0.1587 = 0.6826
\]

\subsection{Geometric Distribution}

A random variable \(X \in \Naturals_0\) with 
\(\Prob(X = n) = p(1 - p)^n\) for some \(p \in (0, 1)\) and \(n \in \Naturals_0\) 
is geometrically distributed. The distribution \(\Prob_X\) is called the \emph{geometric distribution}.

Similar to the binomial distribution, the \emph{geometric} \(\mathcal{G}(n, p)\) distribution is used for an experiment with two 
outcomes, and we want to know the probability of \(k - 1\) non-successes until a success happens  

\[
    \Prob(X = k) = (1 - p)^{k - 1}p
\]

We also get

\[
    \Expc[X] = \mu = \frac{1 - p}{p}
\]

\[
    \Var = \frac{1 - p}{p^2}
\]

and 

\[
    \sigma = \sqrt{\Var(X)}
\]

\subsection{Poisson Distribution}

A random variable \(X \in \Naturals_0\) with 

\[
    \Prob(X = n) = \frac{\lambda^n}{n!} e^{-\lambda}, \quad \text{ for some } \lambda > 0,
\] 

We also define the distribution function 

\[
    \mathbb{F}_X(n) = \sum_{i = 0}^{n} \frac{\lambda^i}{i!} i^{-\lambda}
\]

is Poisson distributed. The distribution \(\Prob_X\) is called the \emph{Poisson distribution} \(\text{Poi}(\lambda)\)
In simple words, it is the number of events x, in a specific interval. This is 
a limit of the binomial distribution for large \(n\) and small \(p\).

We also get our expected result and variance 

\[
    \Expc[X] = \lambda = np
\]

and 

\[
    \Var(X) = \lambda
\]

\subsection{Hyper-geometric Distribution}

Similar to the binomial distribution, but we keep track of the changes after each choice. In other words, 
binomial distribution without repetition. We notate this as \(\text{HG}(M, N, n)\).

\[
    \Prob(X = k) = \frac{\binom{M}{k} \binom{N - M}{n - k}}{\binom{N}{n}}
\]

\textbf{Nomenclature:}

\begin{itemize}

    \item \(N\): Total number of elements

    \item \(M\): Elements with the trait \(A\)

    \item \(N - M\): Elements without the trait \(A\)

    \item \(k\): Number to elements to take

    \item \(n\): Number of iterations

\end{itemize}

Each part of the formula has a different meaning. \(\binom{N}{n}\) represents the total number of ways to choose the elements from the total.
\(\binom{M}{k}\) gives us the ways of choose \(k\) elements with the trait from its total \(M\) and finally, \(\binom{N - M}{n - k}\) represents the remaining ways of choosing 
elements we are not interested in.

We also get 

\[
    \Expc[X] = n \frac{M}{N}
\]

\[
    \Var(X) = \Expc[X]\left(1 - \frac{M}{N}\right) \left(\frac{N - n}{N - 1}\right)
\]

\subsection{The Expected Value for Discrete Random Variables}

Given \(\Omega, \mathcal{A}, \Prob\), a probability space and \(X\) a discrete random variable. We 
define the \emph{expected result} as 

\[
    \Expc(X) = \sum_{x \in X(\Omega)} x \Prob(X = x)
\]

which exists only if 

\[
    \sum_{x \in X(\Omega)} |x| \Prob(X = x) < \infty
\]

Where \(x\) is an event \(\Prob(X = x)\) its respective probability. It represents the mean of the random variable.

\subsubsection{Transformation of the  Expected Value}

Given \(u: X(\Omega) \to \Reals\) where \(\sum_{x \in X(\Omega)} |u(x)|p(x) < \infty\) then 

\[
    \Expc[u(X)] = \sum_{x \in X(\Omega)} u(x)\Prob(X = x)
\] 

This represents the expectation of the function.

\subsection{Triangle Inequality for  Expected Values}

\[
    |\Expc[X]| \le \Expc[|X|]
\]

\textbf{Proof:}

\begin{align*}	
    |\Expc[X]| &= \left| \sum_{x \in X(\Omega)} x \Prob(X = x) \right| \le \sum_{x \in X(\Omega)} |x \Prob(X = x)| \\ 
		    &= \sum_{x \in X(\Omega)} |x| \Prob(X = x) = \Expc [|X|]
\end{align*}

\QED

\subsubsection{Properties of  Expected Values}

Given two random variables \(X\) and \(Y\), if both have an expected results then 

\begin{itemize}
	
    \item \(\Expc[\alpha X] = \alpha \Expc[X]\)

    \item \(\Expc[X + Y] = \Expc[X] + \Expc[Y]\)

    \item \(\Expc[b] = b\)
    
    \item \(X \le Y = \Expc[X] \le \Expc[Y]\)

\end{itemize}

\subsection{Variance}

Given a random variable \(X\) for which \(\Expc[(X - \Expc)^2]\) exists. The we define 
the \emph{variance} of \(X\) as 

\[
    \Var(X) = \Expc[(X - \Expc)^2] = \sum_{x \in X} (x -  \Expc^2)\Prob(X = x)
\]

And its root is the \emph{standard deviation}.

\subsubsection{Properties of the Variance}

Let \( X \) be a (discrete) random variable for which the variance exists.  
Then the following hold:

\begin{itemize}

    \item \(\Var(aX + b) = a^2 \, \Var(X)\), for \( a, b \in \Reals \)
    
    \item \(\Var(X) = \Expc[X^2] - (\Expc[X])^2\)
    
    \item For \( a \in \Reals \), we have  \(\Expc[(X - a)^2] = \Var(X) + (\Expc[X] - a)^2\),  
    and in particular, \(\Expc[(X - a)^2] \ge \Var(X)\).  
    Equality holds if and only if \( a = \Expc[X] \).

\end{itemize}

\textbf{Example:}

Given \(\Expc(X) = 1.2\) and \(\Prob(X = 0) = 0.16, \quad \Prob(X = 1) = 0.48, \Prob(X = 2) = 0.36\). 

\[
    \Expc[X^2] =  0^2 (0.16) + 1^2(0.48) + 2^2(0.36) = 1.92
\]

\[
    \Var(X) = \Expc[(X - \Expc)^2] = (0 - 1.2)^2 (0.16) + (1 - 1.2)^2(0.48) + (2 - 1.2)^2(0.36)
\]

\subsection{Moments}

For a random variable \(X\), we define \(k\). \emph{moment} as \(\Expc[X^k]\)

\subsubsection{Markov Inequality}

Given a random variable \(X\), \(a \in \Reals\) and \(h: D \to [0, \infty)\) a monotonic growing 
function with the properties \(h(a) > 0\) and \(X(\Omega) \subseteq D\) then 

\[
    \Prob(X \ge a) \le \frac{\Expc[h(X)]}{h(a)}
\]

Simpler, 

\[
    \Prob(X \ge a) \le \frac{\Expc[X]}{a}
\]

There is a special case for \(Y = |X|, a > 0\) and \(h(x) = x\) 

\[    
    \Prob(X \ge a) \le \frac{\Expc[h(X)]}{a}
\]

\subsubsection{Chebychev Inequality}

Given a random variable \(X\) with a variance and \(a > 0\) then 

\[
    \Prob(|X - \Expc[X]| \ge a) \le \frac{\Var(X)}{a^2}
\]

This states that the probability of \(X\) is at least \(a\) away of its mean can not be too big.

\subsection{Probability Density}

A Lebesgue-integrable function \( f : \Reals \to [0, \infty) \) is called the (probability)
\emph{density} or \emph{density function} of the random variable \( X \) or of the
distribution \( \Prob_X \) if, for all \( a, b \in \Reals \) with \( a \le b \), the following holds:

\[
    \Prob(a < X \le b) = \Prob_X((a, b]) = \int_a^b f(x)\,dx.
\]

Distributions that possess a probability density are called \emph{continuous distributions}.

\subsubsection{Properties of Continuous Distributions}

\begin{itemize}
	
    \item \(\mathbb{F}_X \) is continuous at \( x \) if and only if \( \Prob(X = x) = 0 \).

    \item 
	\[
	    \int_{-\infty}^{\infty} f_X(x)\,dx 
	    = \mathbb{F}_X(\infty) 
	    = \lim_{x \to \infty} P(X \le x) 
	    = 1.
	\]

    \item  If \( X \) is a continuous random variable, then \( F_X \) is continuous.

\end{itemize}

\subsubsection{How to Test if a Function words as a Density}

To test if given a function it can be used as a density functions we test:

\begin{itemize}
	
    \item \(f(x) \ge 0 \forall x \in \Reals \)

    \item \(\int_{-\infty}^{\infty} f(x) dx = 1\)

\end{itemize}

\subsubsection{Zero Property}

Given a continuous random variable \(X\) then 

For \(a, b \in \Reals\)

\[
    \Prob(a \le X \le b ) = F_X (b) - F_X (a) = \int_{a}^{b} f_X(x)dx = \Prob(a < X \le b)
\]

Also \(A \in \mathcal{B}(\Reals): \Prob(X \in A) = \int_A f_X (x)dx\)

And \(A \in \mathcal{B}(\Reals) \text{ (discrete) }: A = \{a_i\}_{i \in I}, I \in \Naturals :\) 

\[
    \Prob(X \in A) = \sum_{i \in I} \Prob(X = a_i) = 0
\]

\subsection{Expected Value for Continuous Random Variables}

Given a continuous random variable \(X\) with a density \(f_X\). The \emph{expected value}
of \(X\) exists if \(\int |x|f_X(x)dx , \infty\) In that case we define it as 

\[
    \Expc[X] = \int x f_X (x)dx 
\]

We also get all of its properties like for the discrete case.

\subsubsection{Transformation Lemma}

Given a continuous random variable \(X\) with a density \(f\) and a measurable function \(u: \Reals \to \Reals\) 
with \(\int |u(x)|f(x)dx < \infty\) then the following applies 

\[
    \Expc[u(X)] = \int u(x) f(x) dx
\]

\subsubsection{Continuous Uniform Distribution}

A random variable \(X \in [0,1]\) with 

\[
    \Prob (X \le x) \begin{cases}
	0 &, \text{ if } x < 0 \\
	x &, \text{ if } x \in [0,1] \\
	1 &, \text{ if } x > 1 \\
    \end{cases}
\]

is considered \emph{continuous equally distributed}. The distribution function 
\(\Prob_X\) is called \emph{continuous uniform distribution}. Generalized 

\[
    f(x) = \frac{1}{b  - a}
\]

And 

\[
    \Prob (X \le x) = \frac{x - a}{b - a}, x \in [a, b]
\]

with 

\[
    \Expc[X] =  \frac{a + b}{2}
\]
    
\[
    \Var(X) = \frac{(b - a)^2}{12}
\]

\subsection{Exponential Distribution}

We define the \emph{exponential distribution} \(\mathcal{E}(\lambda)\)as a real defined random variable, used mostly 
for the duration of time intervals.

\[
    f(n) = \begin{cases}
	\lambda e^{- \lambda n} &, n \ge 0 \\ 
	0 &, \text{ else }
    \end{cases} 
\] 

We also define the distribution function 

\[
    \mathbb{F}_X(X = n) = \int_{- \infty}^{n} \Prob(X = n) = \begin{cases}
	1 - e^{- \lambda n} &, n \ge 0 \\ 
	0 &, \text{ else }
    \end{cases} 
\]

We also have 

     
\[
    \Expc(X) = \frac{1}{\lambda}
\]
    
\[
    \Var(X) = \frac{1}{\lambda^2}
\]
    

And even the following property 

\[
    \Prob (X \ge x + y \mid X > y) = e^{\lambda x} = \Prob(X \ge x)
\]

This distribution is memory-less. This means that the future probabilities of an event are independent 
of the previous ones. 

\subsection{Chi-Square Distribution}

Given a random variable \(X\) with density 

\[
    f(x) = \frac{1}{2^{\frac{n}{2}} \Gamma \left(\frac{n}{2}\right)} x^{\frac{n}{2 - 1}}e^{\frac{-x}{2}}
\]

We also have 

\[
    \Expc[X] = n
\]
    
\[
    \Var(X) = \Expc[X] 2n
\]

\subsection{Transformation Theorem for Densities}

Given a random variable \(X\) with values in the open interval \(I \subseteq \Reals\) and the density \(f_X\). If 
\(j \subseteq \Reals\) is an open interval and \(u: I \to J\) is a diffeomorphism then has \(Y = u(X)\) the density 

\[
    f_Y (y) = f_X(u^{-1}(y)) | (u^{-1})'(y)|
\]

For \(y \in J\) and \(f_Y(y) = 0\) for \(y \in \Reals \setminus J\).

\subsection{Quantile}

Let \( X \) be a random variable with distribution \( F \).
For \( p \in (0, 1) \), a value \( q_p \) is called a \emph{p-quantile} of \( X \) (or of \( F \)) if:

\[
    \Prob(X \le q_p) \ge p \text{ and }\Prob(q_p \le X) \ge 1 - p,
\]

or equivalently,

\[
    F(q_p) \ge p \text{ and } \lim_{x \nearrow q_p} F(x) \le p.
\]

In general, the \( p \)-quantile is not unique.
If \( F \) is strictly increasing and continuous, then \( q_p \) is unique.
If \( q_p \) is not unique, we can make it “unique” by defining the smallest quantile as

\[
    F^{-1}(p) = \inf \{ x \in \Reals : F(x) \ge p \}.
\]

